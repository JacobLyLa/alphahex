{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from hex import HexGame\n",
    "from neuralnet import createModel, loadModel\n",
    "from player import NeuralNetPlayer, RandomPlayer, MCTSPlayer, NeuralMCTSPlayer\n",
    "from tournament import Tournament\n",
    "import pickle\n",
    "from mcts import Mcts\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "boardSize = 3\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jacob\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralMCTS won 3 times, lost 5 times, and drew 0 times\n",
      "MCTS won 5 times, lost 3 times, and drew 0 times\n"
     ]
    }
   ],
   "source": [
    "# load model.4 and bestmodel.4\n",
    "model = loadModel(f'model.{boardSize}')\n",
    "bestModel = loadModel(f'bestmodel.{boardSize}')\n",
    "\n",
    "mctsPlayer = MCTSPlayer(maxIters=25, maxTime=1000)\n",
    "nnMctsPlayer = NeuralMCTSPlayer(model=model, maxIters=25, maxTime=1000)\n",
    "tournament = Tournament(HexGame, [nnMctsPlayer, mctsPlayer], boardSize=boardSize, plot=True)\n",
    "tournament.run(4)\n",
    "tournament.printResults()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential games comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jacob\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuralnet Player: 2 wins, 2 losses, 0 draws\n",
      "Length of replay buffer: 26\n"
     ]
    }
   ],
   "source": [
    "rounds = 4\n",
    "# model = createModel(size=boardSize)\n",
    "model = loadModel(f'model.{boardSize}')\n",
    "neuralNetPlayer = NeuralNetPlayer(model=model, argmax=True)\n",
    "randomPlayer = RandomPlayer()\n",
    "tournament = Tournament(HexGame, neuralNetPlayer, randomPlayer, boardSize=boardSize, plot=True)\n",
    "tournament.run(rounds)\n",
    "wins, losses, draws = tournament.getResults()\n",
    "print(f\"Neuralnet Player: {wins} wins, {losses} losses, {draws} draws\")\n",
    "\n",
    "replay = nnMctsPlayer.mcts.replayBuffer\n",
    "# TODO: flip both axis and double the replay buffer\n",
    "print(f'Length of replay buffer: {len(replay)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model on replay buffer\n",
    "X = np.array([x[0] for x in replay]).reshape(len(replay), boardSize*boardSize)\n",
    "y = np.array([x[1] for x in replay]).reshape(len(replay), boardSize*boardSize)\n",
    "model.fit(X, y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new game\n",
    "game = HexGame(None, None, size=3)\n",
    "board = game.getNNState()\n",
    "# prediction = model.predict(board)\n",
    "\n",
    "# plot distribution of actions predictions of empty board\n",
    "# plt.scatter(range(len(prediction[0])), prediction[0])\n",
    "\n",
    "# plot distribution actions of empty board with mcts\n",
    "mc = Mcts(maxIters=5000, maxTime=15)\n",
    "mc.search(game)\n",
    "dist = mc.replayBuffer\n",
    "plt.scatter(range(len(dist[0][-1])), dist[0][-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check who wins by counting 1's and -1's in last layer of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 5\n",
    "dataName = f'replayBuffer{s}.pickle'\n",
    "with open(dataName, 'rb') as f:\n",
    "    replay = pickle.load(f)\n",
    "\n",
    "X = np.array([x[0] for x in replay]).reshape(len(replay),-1)\n",
    "y = np.array([x[1] for x in replay]).reshape(len(replay),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(size=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = [game.getNNState()[0] for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = np.array(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load replaybuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName = f'replayBuffer{boardSize}.pickle'\n",
    "with open(dataName, 'rb') as f:\n",
    "    replay = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([x[0] for x in replay]).reshape(len(replay), boardSize*boardSize)\n",
    "y = np.array([x[1] for x in replay]).reshape(len(replay), boardSize*boardSize)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "numModels = 5\n",
    "models = []\n",
    "\n",
    "for i in range(numModels):\n",
    "    newModel = tf.keras.models.clone_model(model)\n",
    "    newModel.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.01))\n",
    "    newModel.fit(X, y, epochs=20, verbose=0)\n",
    "    models.append(newModel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test vs random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_better = 0\n",
    "total_wins = []\n",
    "for i in range(numModels):\n",
    "    tournament = Tournament(HexGame, NeuralNetPlayer(model=models[i]), RandomPlayer(), boardSize=boardSize)\n",
    "    tournament.run(11)\n",
    "    wins, losses, draws = tournament.getResults()\n",
    "    total_wins.append(wins)\n",
    "    if wins > losses:\n",
    "        nn_better += 1\n",
    "    print(f\"Model {i} vs random: {wins} wins, {losses} losses, {draws} draws\")\n",
    "\n",
    "    tournament = Tournament(HexGame, NeuralNetPlayer(model=models[i]),  MCTSPlayer(maxIters=50, maxTime=20), boardSize=boardSize)\n",
    "    tournament.run(11)\n",
    "    wins, losses, draws = tournament.getResults()\n",
    "    total_wins.append(wins)\n",
    "    if wins > losses:\n",
    "        nn_better += 1\n",
    "    print(f\"Model {i} vs mcts: {wins} wins, {losses} losses, {draws} draws\")\n",
    "\n",
    "print(f\"NN MCTS Player: {nn_better} models better than random player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(total_wins)\n",
    "print(f'winrate: {int(100*sum(total_wins)/len(total_wins)/11)}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]\n",
    "# use %magic to make plots pop up in a separate window\n",
    "tournament = Tournament(HexGame, NeuralNetPlayer(model=model), RandomPlayer(), boardSize=boardSize, plot=True)\n",
    "tournament.run(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e56f9ad386266bf5d5cd9b6002e19566fae980b41617c03a2c39443e844065f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
