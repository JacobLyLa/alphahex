{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from hex import HexGame\n",
    "from neuralnet import createModel, loadModel, createCriticModel\n",
    "from player import NeuralNetPlayer, RandomPlayer, MCTSPlayer, NeuralMCTSPlayer\n",
    "from tournament import Tournament\n",
    "import pickle\n",
    "from mcts import Mcts\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "%matplotlib qt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if NN mcts is better than normal mcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jacob\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting player won 7 times and lost 1 times\n",
      "NeuralMCTS won 3 times, lost 5 times, and drew 0 times\n",
      "MCTS won 5 times, lost 3 times, and drew 0 times\n"
     ]
    }
   ],
   "source": [
    "boardSize = 4\n",
    "bestModel = loadModel(f'model.{boardSize}')\n",
    "\n",
    "mctsPlayer = MCTSPlayer(maxIters=10, maxTime=1000)\n",
    "nnMctsPlayer = NeuralMCTSPlayer(model=bestModel, maxIters=10, maxTime=1000)\n",
    "tournament = Tournament(HexGame, [nnMctsPlayer, mctsPlayer], boardSize=boardSize, plot=True)\n",
    "tournament.run(4)\n",
    "tournament.printResults()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data for critic\n",
    "boardSize = 4\n",
    "# Let two mcts players play against each other\n",
    "mctsPlayer1 = MCTSPlayer(maxIters=100, maxTime=1000, argmax=True)\n",
    "mctsPlayer2 = MCTSPlayer(maxIters=100, maxTime=1000, argmax=True)\n",
    "tournament = Tournament(HexGame, [mctsPlayer1, mctsPlayer2], boardSize=boardSize, plot=False)\n",
    "tournament.run(200)\n",
    "tournament.printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get replay buffer from each players\n",
    "replayBuffer = mctsPlayer1.mcts.replayBuffer + mctsPlayer2.mcts.replayBuffer\n",
    "print(f'Length of replay buffer: {len(replayBuffer)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [r[0] for r in replayBuffer]\n",
    "y = [r[-1] for r in replayBuffer]\n",
    "X = np.array(X).reshape(len(X), -1)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "# for all -1's in y set it to 0\n",
    "y[y == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# CRITIC\n",
    "def createCriticModel(size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(size*size, input_dim=size*size+size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # dropout layer\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # Add another Dense layer\n",
    "    model.add(Dense(size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # Add another dropout layer\n",
    "    model.add(Dropout(0.3))\n",
    "    # final layer is a singular value from 0 to 1\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='he_uniform'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback to stop training when validation accuracy has stopped improving\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, mode='max', restore_best_weights=True)\n",
    "# Model checkpoint callback to save the best model weights during training\n",
    "model_checkpoint = ModelCheckpoint('best_model_weights.h5', monitor='val_accuracy', save_best_only=True, verbose=0, mode='max')\n",
    "\n",
    "critic = createCriticModel(boardSize)\n",
    "# split into train and test\n",
    "X_train = X[:int(len(X)*0.8)]\n",
    "y_train = y[:int(len(y)*0.8)]\n",
    "X_test = X[int(len(X)*0.8):]\n",
    "y_test = y[int(len(y)*0.8):]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# train model until convergence\n",
    "history = critic.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), verbose=0, batch_size=64, callbacks=[early_stopping, model_checkpoint], shuffle=True)\n",
    "critic.load_weights('best_model_weights.h5')\n",
    "# print val accuracy and loss\n",
    "print(f'Val accuracy: {history.history[\"val_accuracy\"][-1]}')\n",
    "print(f'Val loss: {history.history[\"val_loss\"][-1]}')\n",
    "print(f'Mean of y_test: {np.mean(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy \n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### critic in real-time game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = MCTSPlayer(maxIters=100, maxTime=1000, argmax=True)\n",
    "player2 = MCTSPlayer(maxIters=100, maxTime=1000, argmax=True)\n",
    "\n",
    "game = HexGame(None, None, boardSize, plot=False)\n",
    "turn = 0\n",
    "while not game.isTerminal():\n",
    "    print(critic.predict(game.getNNState(), verbose=0)[0][0])\n",
    "    if turn % 2 == 0:\n",
    "        player1.playAction(game)\n",
    "    else:\n",
    "        player2.playAction(game)\n",
    "    turn += 1\n",
    "print(\"winner is: \", game.getResult())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test how good on last move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = MCTSPlayer(maxIters=100, maxTime=1000, argmax=True)\n",
    "player2 = MCTSPlayer(maxIters=100, maxTime=1000, argmax=True)\n",
    "\n",
    "correct = 0\n",
    "for _ in range(20):\n",
    "    game = HexGame(None, None, boardSize, plot=False)\n",
    "    turn = 0\n",
    "    while not game.isTerminal():\n",
    "        lastState = game.getNNState()\n",
    "        if turn % 2 == 0:\n",
    "            player1.playAction(game)\n",
    "        else:\n",
    "            player2.playAction(game)\n",
    "        turn += 1\n",
    "    pred = critic.predict(lastState, verbose=0)[0][0]\n",
    "    print(f'Prediction: {pred}, Actual: {game.getResult()}')\n",
    "    if pred > 0.5 and game.getResult() == 1:\n",
    "        correct += 1\n",
    "    elif pred < 0.5 and game.getResult() == -1:\n",
    "        correct += 1\n",
    "\n",
    "print(f'Accuracy: {correct/20}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential games comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 4\n",
    "# model = createModel(size=boardSize)\n",
    "model = loadModel(f'model.{boardSize}')\n",
    "neuralNetPlayer = NeuralNetPlayer(model=model, argmax=True)\n",
    "randomPlayer = RandomPlayer()\n",
    "tournament = Tournament(HexGame, neuralNetPlayer, randomPlayer, boardSize=boardSize, plot=True)\n",
    "tournament.run(rounds)\n",
    "wins, losses, draws = tournament.getResults()\n",
    "print(f\"Neuralnet Player: {wins} wins, {losses} losses, {draws} draws\")\n",
    "\n",
    "replay = nnMctsPlayer.mcts.replayBuffer\n",
    "# TODO: flip both axis and double the replay buffer\n",
    "print(f'Length of replay buffer: {len(replay)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model on replay buffer\n",
    "X = np.array([x[0] for x in replay]).reshape(len(replay), boardSize*boardSize)\n",
    "y = np.array([x[1] for x in replay]).reshape(len(replay), boardSize*boardSize)\n",
    "model.fit(X, y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new game\n",
    "game = HexGame(None, None, size=3)\n",
    "board = game.getNNState()\n",
    "# prediction = model.predict(board)\n",
    "\n",
    "# plot distribution of actions predictions of empty board\n",
    "# plt.scatter(range(len(prediction[0])), prediction[0])\n",
    "\n",
    "# plot distribution actions of empty board with mcts\n",
    "mc = Mcts(maxIters=5000, maxTime=15)\n",
    "mc.search(game)\n",
    "dist = mc.replayBuffer\n",
    "plt.scatter(range(len(dist[0][-1])), dist[0][-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check who wins by counting 1's and -1's in last layer of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 5\n",
    "dataName = f'replayBuffer{s}.pickle'\n",
    "with open(dataName, 'rb') as f:\n",
    "    replay = pickle.load(f)\n",
    "\n",
    "X = np.array([x[0] for x in replay]).reshape(len(replay),-1)\n",
    "y = np.array([x[1] for x in replay]).reshape(len(replay),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(size=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = [game.getNNState()[0] for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = np.array(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load replaybuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName = f'replayBuffer{boardSize}.pickle'\n",
    "with open(dataName, 'rb') as f:\n",
    "    replay = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([x[0] for x in replay]).reshape(len(replay), boardSize*boardSize)\n",
    "y = np.array([x[1] for x in replay]).reshape(len(replay), boardSize*boardSize)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "numModels = 5\n",
    "models = []\n",
    "\n",
    "for i in range(numModels):\n",
    "    newModel = tf.keras.models.clone_model(model)\n",
    "    newModel.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.01))\n",
    "    newModel.fit(X, y, epochs=20, verbose=0)\n",
    "    models.append(newModel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test vs random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_better = 0\n",
    "total_wins = []\n",
    "for i in range(numModels):\n",
    "    tournament = Tournament(HexGame, NeuralNetPlayer(model=models[i]), RandomPlayer(), boardSize=boardSize)\n",
    "    tournament.run(11)\n",
    "    wins, losses, draws = tournament.getResults()\n",
    "    total_wins.append(wins)\n",
    "    if wins > losses:\n",
    "        nn_better += 1\n",
    "    print(f\"Model {i} vs random: {wins} wins, {losses} losses, {draws} draws\")\n",
    "\n",
    "    tournament = Tournament(HexGame, NeuralNetPlayer(model=models[i]),  MCTSPlayer(maxIters=50, maxTime=20), boardSize=boardSize)\n",
    "    tournament.run(11)\n",
    "    wins, losses, draws = tournament.getResults()\n",
    "    total_wins.append(wins)\n",
    "    if wins > losses:\n",
    "        nn_better += 1\n",
    "    print(f\"Model {i} vs mcts: {wins} wins, {losses} losses, {draws} draws\")\n",
    "\n",
    "print(f\"NN MCTS Player: {nn_better} models better than random player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(total_wins)\n",
    "print(f'winrate: {int(100*sum(total_wins)/len(total_wins)/11)}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]\n",
    "# use %magic to make plots pop up in a separate window\n",
    "tournament = Tournament(HexGame, NeuralNetPlayer(model=model), RandomPlayer(), boardSize=boardSize, plot=True)\n",
    "tournament.run(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e56f9ad386266bf5d5cd9b6002e19566fae980b41617c03a2c39443e844065f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
