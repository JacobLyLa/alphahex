{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from hex import HexGame\n",
    "from neuralnet import createModel, loadModel, createCriticModel\n",
    "from player import NeuralNetPlayer, RandomPlayer, MCTSPlayer, NeuralMCTSPlayer\n",
    "from tournament import Tournament\n",
    "import pickle\n",
    "from mcts import Mcts\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "%matplotlib qt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if NN mcts is better than normal mcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boardSize = 4\n",
    "bestModel = loadModel(f'bestmodel.{boardSize}')\n",
    "\n",
    "mctsPlayer = MCTSPlayer(maxIters=25, maxTime=1000)\n",
    "nnMctsPlayer = NeuralMCTSPlayer(model=bestModel, maxIters=25, maxTime=1000)\n",
    "tournament = Tournament(HexGame, [nnMctsPlayer, mctsPlayer], boardSize=boardSize, plot=True)\n",
    "tournament.run(4)\n",
    "tournament.printResults()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting player won 259 times and lost 141 times\n",
      "MCTS won 199 times, lost 201 times, and drew 0 times\n",
      "MCTS won 201 times, lost 199 times, and drew 0 times\n"
     ]
    }
   ],
   "source": [
    "# create data for critic\n",
    "boardSize = 4\n",
    "# Let two mcts players play against each other\n",
    "mctsPlayer1 = MCTSPlayer(maxIters=100, maxTime=1000, argmax=True)\n",
    "mctsPlayer2 = MCTSPlayer(maxIters=100, maxTime=1000, argmax=True)\n",
    "tournament = Tournament(HexGame, [mctsPlayer1, mctsPlayer2], boardSize=boardSize, plot=False)\n",
    "tournament.run(200)\n",
    "tournament.printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of replay buffer: 3615\n"
     ]
    }
   ],
   "source": [
    "# get replay buffer from each players\n",
    "replayBuffer = mctsPlayer1.mcts.replayBuffer + mctsPlayer2.mcts.replayBuffer\n",
    "print(f'Length of replay buffer: {len(replayBuffer)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [r[0] for r in replayBuffer]\n",
    "y = [r[-1] for r in replayBuffer]\n",
    "X = np.array(X).reshape(len(X), -1)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "# for all -1's in y set it to 0\n",
    "y[y == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# CRITIC\n",
    "def createCriticModel(size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(size*size, input_dim=size*size+size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # dropout layer\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # Add another Dense layer\n",
    "    model.add(Dense(size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # Add another dropout layer\n",
    "    model.add(Dropout(0.3))\n",
    "    # final layer is a singular value from 0 to 1\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='he_uniform'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2892, 20)\n",
      "(2892, 1)\n",
      "(723, 20)\n",
      "(723, 1)\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Epoch 63: early stopping\n",
      "Val accuracy: 0.7123098373413086\n",
      "Val loss: 0.5574069619178772\n",
      "Mean of y_test: 0.6113416320885201\n"
     ]
    }
   ],
   "source": [
    "# Early stopping callback to stop training when validation accuracy has stopped improving\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, mode='max', restore_best_weights=True)\n",
    "# Model checkpoint callback to save the best model weights during training\n",
    "model_checkpoint = ModelCheckpoint('best_model_weights.h5', monitor='val_accuracy', save_best_only=True, verbose=0, mode='max')\n",
    "\n",
    "critic = createCriticModel(boardSize)\n",
    "# split into train and test\n",
    "X_train = X[:int(len(X)*0.8)]\n",
    "y_train = y[:int(len(y)*0.8)]\n",
    "X_test = X[int(len(X)*0.8):]\n",
    "y_test = y[int(len(y)*0.8):]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# train model until convergence\n",
    "history = critic.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), verbose=0, batch_size=64, callbacks=[early_stopping, model_checkpoint], shuffle=True)\n",
    "critic.load_weights('best_model_weights.h5')\n",
    "# print val accuracy and loss\n",
    "print(f'Val accuracy: {history.history[\"val_accuracy\"][-1]}')\n",
    "print(f'Val loss: {history.history[\"val_loss\"][-1]}')\n",
    "print(f'Mean of y_test: {np.mean(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy \n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### critic in real-time game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6491817\n",
      "0.46109477\n",
      "0.4824482\n",
      "0.33125588\n",
      "0.32222277\n",
      "0.2847189\n",
      "0.22229151\n",
      "0.2580883\n",
      "winner is:  -1\n"
     ]
    }
   ],
   "source": [
    "player1 = MCTSPlayer(maxIters=100, maxTime=1000, argmax=True)\n",
    "player2 = MCTSPlayer(maxIters=100, maxTime=1000, argmax=True)\n",
    "\n",
    "game = HexGame(None, None, boardSize, plot=False)\n",
    "turn = 0\n",
    "while not game.isTerminal():\n",
    "    print(critic.predict(game.getNNState(), verbose=0)[0][0])\n",
    "    if turn % 2 == 0:\n",
    "        player1.playAction(game)\n",
    "    else:\n",
    "        player2.playAction(game)\n",
    "    turn += 1\n",
    "print(\"winner is: \", game.getResult())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test how good on last move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.8352087140083313, Actual: 1\n",
      "Prediction: 0.6477511525154114, Actual: 1\n",
      "Prediction: 0.9251713156700134, Actual: 1\n",
      "Prediction: 0.30397605895996094, Actual: -1\n",
      "Prediction: 0.20696748793125153, Actual: 1\n",
      "Prediction: 0.8370585441589355, Actual: 1\n",
      "Prediction: 0.598253071308136, Actual: 1\n",
      "Prediction: 0.9804055690765381, Actual: 1\n",
      "Prediction: 0.8845412731170654, Actual: 1\n",
      "Prediction: 0.20940864086151123, Actual: -1\n",
      "Prediction: 0.669664204120636, Actual: 1\n",
      "Prediction: 0.3395485281944275, Actual: 1\n",
      "Prediction: 0.3352910876274109, Actual: -1\n",
      "Prediction: 0.7537873983383179, Actual: 1\n",
      "Prediction: 0.5791076421737671, Actual: -1\n",
      "Prediction: 0.8391754627227783, Actual: 1\n",
      "Prediction: 0.36929917335510254, Actual: -1\n",
      "Prediction: 0.6987243890762329, Actual: 1\n",
      "Prediction: 0.8374888300895691, Actual: 1\n",
      "Prediction: 0.9558698534965515, Actual: 1\n",
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "player1 = MCTSPlayer(maxIters=100, maxTime=1000, argmax=True)\n",
    "player2 = MCTSPlayer(maxIters=100, maxTime=1000, argmax=True)\n",
    "\n",
    "correct = 0\n",
    "for _ in range(20):\n",
    "    game = HexGame(None, None, boardSize, plot=False)\n",
    "    turn = 0\n",
    "    while not game.isTerminal():\n",
    "        lastState = game.getNNState()\n",
    "        if turn % 2 == 0:\n",
    "            player1.playAction(game)\n",
    "        else:\n",
    "            player2.playAction(game)\n",
    "        turn += 1\n",
    "    pred = critic.predict(lastState, verbose=0)[0][0]\n",
    "    print(f'Prediction: {pred}, Actual: {game.getResult()}')\n",
    "    if pred > 0.5 and game.getResult() == 1:\n",
    "        correct += 1\n",
    "    elif pred < 0.5 and game.getResult() == -1:\n",
    "        correct += 1\n",
    "\n",
    "print(f'Accuracy: {correct/20}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential games comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tournament.__init__() got multiple values for argument 'boardSize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m neuralNetPlayer \u001b[39m=\u001b[39m NeuralNetPlayer(model\u001b[39m=\u001b[39mmodel, argmax\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m randomPlayer \u001b[39m=\u001b[39m RandomPlayer()\n\u001b[1;32m----> 6\u001b[0m tournament \u001b[39m=\u001b[39m Tournament(HexGame, neuralNetPlayer, randomPlayer, boardSize\u001b[39m=\u001b[39;49mboardSize, plot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      7\u001b[0m tournament\u001b[39m.\u001b[39mrun(rounds)\n\u001b[0;32m      8\u001b[0m wins, losses, draws \u001b[39m=\u001b[39m tournament\u001b[39m.\u001b[39mgetResults()\n",
      "\u001b[1;31mTypeError\u001b[0m: Tournament.__init__() got multiple values for argument 'boardSize'"
     ]
    }
   ],
   "source": [
    "rounds = 4\n",
    "# model = createModel(size=boardSize)\n",
    "model = loadModel(f'model.{boardSize}')\n",
    "neuralNetPlayer = NeuralNetPlayer(model=model, argmax=True)\n",
    "randomPlayer = RandomPlayer()\n",
    "tournament = Tournament(HexGame, neuralNetPlayer, randomPlayer, boardSize=boardSize, plot=True)\n",
    "tournament.run(rounds)\n",
    "wins, losses, draws = tournament.getResults()\n",
    "print(f\"Neuralnet Player: {wins} wins, {losses} losses, {draws} draws\")\n",
    "\n",
    "replay = nnMctsPlayer.mcts.replayBuffer\n",
    "# TODO: flip both axis and double the replay buffer\n",
    "print(f'Length of replay buffer: {len(replay)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model on replay buffer\n",
    "X = np.array([x[0] for x in replay]).reshape(len(replay), boardSize*boardSize)\n",
    "y = np.array([x[1] for x in replay]).reshape(len(replay), boardSize*boardSize)\n",
    "model.fit(X, y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new game\n",
    "game = HexGame(None, None, size=3)\n",
    "board = game.getNNState()\n",
    "# prediction = model.predict(board)\n",
    "\n",
    "# plot distribution of actions predictions of empty board\n",
    "# plt.scatter(range(len(prediction[0])), prediction[0])\n",
    "\n",
    "# plot distribution actions of empty board with mcts\n",
    "mc = Mcts(maxIters=5000, maxTime=15)\n",
    "mc.search(game)\n",
    "dist = mc.replayBuffer\n",
    "plt.scatter(range(len(dist[0][-1])), dist[0][-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check who wins by counting 1's and -1's in last layer of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 5\n",
    "dataName = f'replayBuffer{s}.pickle'\n",
    "with open(dataName, 'rb') as f:\n",
    "    replay = pickle.load(f)\n",
    "\n",
    "X = np.array([x[0] for x in replay]).reshape(len(replay),-1)\n",
    "y = np.array([x[1] for x in replay]).reshape(len(replay),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(size=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = [game.getNNState()[0] for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = np.array(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load replaybuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName = f'replayBuffer{boardSize}.pickle'\n",
    "with open(dataName, 'rb') as f:\n",
    "    replay = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([x[0] for x in replay]).reshape(len(replay), boardSize*boardSize)\n",
    "y = np.array([x[1] for x in replay]).reshape(len(replay), boardSize*boardSize)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "numModels = 5\n",
    "models = []\n",
    "\n",
    "for i in range(numModels):\n",
    "    newModel = tf.keras.models.clone_model(model)\n",
    "    newModel.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.01))\n",
    "    newModel.fit(X, y, epochs=20, verbose=0)\n",
    "    models.append(newModel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test vs random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_better = 0\n",
    "total_wins = []\n",
    "for i in range(numModels):\n",
    "    tournament = Tournament(HexGame, NeuralNetPlayer(model=models[i]), RandomPlayer(), boardSize=boardSize)\n",
    "    tournament.run(11)\n",
    "    wins, losses, draws = tournament.getResults()\n",
    "    total_wins.append(wins)\n",
    "    if wins > losses:\n",
    "        nn_better += 1\n",
    "    print(f\"Model {i} vs random: {wins} wins, {losses} losses, {draws} draws\")\n",
    "\n",
    "    tournament = Tournament(HexGame, NeuralNetPlayer(model=models[i]),  MCTSPlayer(maxIters=50, maxTime=20), boardSize=boardSize)\n",
    "    tournament.run(11)\n",
    "    wins, losses, draws = tournament.getResults()\n",
    "    total_wins.append(wins)\n",
    "    if wins > losses:\n",
    "        nn_better += 1\n",
    "    print(f\"Model {i} vs mcts: {wins} wins, {losses} losses, {draws} draws\")\n",
    "\n",
    "print(f\"NN MCTS Player: {nn_better} models better than random player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(total_wins)\n",
    "print(f'winrate: {int(100*sum(total_wins)/len(total_wins)/11)}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]\n",
    "# use %magic to make plots pop up in a separate window\n",
    "tournament = Tournament(HexGame, NeuralNetPlayer(model=model), RandomPlayer(), boardSize=boardSize, plot=True)\n",
    "tournament.run(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e56f9ad386266bf5d5cd9b6002e19566fae980b41617c03a2c39443e844065f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
